{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Major Flight Delays\n",
    "\n",
    "Our client, FlightChicken, would like a model that predicts whether a flight will experience a major delay. Delays can cause a major disruption to travel plans, especially if they cause a person to miss their connecting flight. FlightChicken would like to give their users a heads up about potential travel disruptions like this.\n",
    "\n",
    "This is a major undertaking as there are hundreds of airlines and thousands of airports in the United States alone. That's why FlightChicken would like to launch with just an MVP to prove our their concept. This MVP should support major US airports and 8 of the most popular airlines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=FutureWarning)\n",
    "\n",
    "import airportsdata\n",
    "from pytz import timezone\n",
    "import pytz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Understanding\n",
    "\n",
    "MVP should support:\n",
    "\n",
    "* [Top 8 US Airlines](https://www.statista.com/statistics/250577/domestic-market-share-of-leading-us-airlines/)\n",
    " * American Airlines\n",
    " * Delta Air Lines\n",
    " * United Airlines\n",
    " * Southwest Airlines\n",
    " * Alaska Airlines\n",
    " * JetBlue Airways\n",
    " * Spirit\n",
    " * SkyWest\n",
    "* [Large and medium airport hubs](https://www.faa.gov/airports/planning_capacity/passenger_allcargo_stats/passenger/media/cy20-commercial-service-enplanements.pdf)\n",
    " * \"The term hub is used by the FAA to identify very busy commercial service airports. Large hubs are the airports that each account for at least one percent of total U.S. passenger enplanements.\"\n",
    " * In 2020 these accounted for 84% of all enplanements\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "To complete this project, we will be using data from several sources.\n",
    "\n",
    "1. **Bureau of Transportation Statistics: Carrier On-Time Performence Database.** This database contains scheduled and actual departure and arrival times reported by certified U.S. air carriers that account for at least one percent of domestic scheduled passenger revenues. The data is collected by the Office of Airline Information, Bureau of Transportation Statistics (BTS).\n",
    "2. **National Oceanic and Atmospheric Administration (NOAA): Daily Weather Summaries:** Data on select weather conditions at airprots collected by weather stations.\n",
    "3. **Timezone for Each Airport by StackOverflow user hroptatyr:** This data will allow us to convert our timedata to UTC and make it easier to work with. [Link](https://raw.githubusercontent.com/hroptatyr/dateutils/tzmaps/iata.tzmap)\n",
    "\n",
    "Additionally, to link data from NOAA to each airport, I manually looked up the weather station for all airports relevant in this project. This data was can be found in FILE PATH. To reproduce, go to [Climate Data Online Search](https://www.ncei.noaa.gov/cdo-web/search) and make the following selections:\n",
    "\n",
    "1. Select Weather Observation Type/Dataset: Daily Summaries\n",
    "2. Select Date Range: 2018-01-01 to 2021-12-31\n",
    "3. Search For: Stations\n",
    "4. Enter a Search Term: enter the city and state of the airport plus the term 'airport'. e.g. Atlanta, GA airport\n",
    "5. Hit 'Search'\n",
    "6. On the results page, find the closest/most relevant weather station. In the example of \"Atlanta, GA airport\" you would select 'Atlanta Hartsfield Jackson International Airport\". Hit 'Add to Cart'. **On the results page, make note of the Station ID. This is what will serve as the key for linking BTS data with weather data.**\n",
    "7. Repeat for every airport.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preperation & Cleaning\n",
    "First, we need to load all our data into pandas so that we can work with it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Carrier On-Time Performence Database\n",
    "This data can only be downloaded by month, which means it is split among many files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-68625596303d>:2: DtypeWarning: Columns (25) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  carrier_data = pd.concat((pd.read_csv(f) for f in flight_data), ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "flight_data = glob.glob(os.path.join('data/downloaded/carrier-on-time-performence', \"*.csv\"))\n",
    "carrier_data = pd.concat((pd.read_csv(f) for f in flight_data), ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Timezone Data\n",
    "Next, we bring in timezone data and merge it into our carrier data from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "timezones = pd.read_csv('data/downloaded/timezones-for-each-airport.csv')\n",
    "carrier_data['ORIGIN_TIMEZONE'] = carrier_data['ORIGIN'].map(timezones.set_index('ORIGIN')['timezone'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2428"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check whether we were able to match all records\n",
    "carrier_data['ORIGIN_TIMEZONE'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like 2,428 records couldn't be matched to a timezone. That's not bad considering we have 25,115,464 records. We'll simply drop the Null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "carrier_data = carrier_data[carrier_data['ORIGIN_TIMEZONE'].notna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The time feature we are concerned with is takeoff time.  Our goal is to convert it to a universal UTC time. To do this, we first need to transform it a bit so that it's workable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FL_DATE</th>\n",
       "      <th>CRS_DEP_TIME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2/26/2018 12:00:00 AM</td>\n",
       "      <td>940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2/26/2018 12:00:00 AM</td>\n",
       "      <td>745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2/26/2018 12:00:00 AM</td>\n",
       "      <td>1814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2/26/2018 12:00:00 AM</td>\n",
       "      <td>1040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2/26/2018 12:00:00 AM</td>\n",
       "      <td>1504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25115459</th>\n",
       "      <td>7/22/2019 12:00:00 AM</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25115460</th>\n",
       "      <td>7/23/2019 12:00:00 AM</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25115461</th>\n",
       "      <td>7/24/2019 12:00:00 AM</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25115462</th>\n",
       "      <td>7/25/2019 12:00:00 AM</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25115463</th>\n",
       "      <td>7/26/2019 12:00:00 AM</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25113036 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        FL_DATE  CRS_DEP_TIME\n",
       "0         2/26/2018 12:00:00 AM           940\n",
       "1         2/26/2018 12:00:00 AM           745\n",
       "2         2/26/2018 12:00:00 AM          1814\n",
       "3         2/26/2018 12:00:00 AM          1040\n",
       "4         2/26/2018 12:00:00 AM          1504\n",
       "...                         ...           ...\n",
       "25115459  7/22/2019 12:00:00 AM          1500\n",
       "25115460  7/23/2019 12:00:00 AM          1500\n",
       "25115461  7/24/2019 12:00:00 AM          1500\n",
       "25115462  7/25/2019 12:00:00 AM          1500\n",
       "25115463  7/26/2019 12:00:00 AM          1500\n",
       "\n",
       "[25113036 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "carrier_data[['FL_DATE', 'CRS_DEP_TIME']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All times are expressed as an integer in military time. For example, 940 is 9:40am and 1500 is 3:00pm. We would like to first convert it to a string that can be read as 24H time, then combined with the FL_DATE field so that we can have an exact take-off date and time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# First we create a helper function to carry out the transformation\n",
    "\n",
    "def float_to_time(time):\n",
    "    '''\n",
    "    Function takes in an integer representation of time (24-hour format)\n",
    "    and returns a string in proper datetime formatting. Example: 1545 (int) becomes 15:45 (string)\n",
    "    '''\n",
    "    time_str = str(time)\n",
    "    digits = len(time_str)\n",
    "    if time_str == \n",
    "    if digits < 2:\n",
    "        return '00:0' + str(time)\n",
    "    if digits == 2:\n",
    "        return '00:' + str(time)\n",
    "    if digits == 3:\n",
    "        return '0' + time_str[:1] + ':' + time_str[1:]\n",
    "    if digits == 4:\n",
    "        return time_str[:2] + ':' + time_str[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# First, we apply the function above to transform the CRS_DEP_TIME field\n",
    "carrier_data['CRS_DEP_TIME'] = carrier_data['CRS_DEP_TIME'].apply(float_to_time)\n",
    "# Next, we update the FL_DATE field so that it now contains the proper date AND time of takeoff\n",
    "carrier_data['FL_DATE'] =  pd.to_datetime(carrier_data['FL_DATE'].astype(str) + ' ' + carrier_data['CRS_DEP_TIME'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the above expressed in LOCAL time, we will use the timezone data to create an additional element in UTC time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# First we need to make our data, which is timezone naive, to timezone aware\n",
    "carrier_data['FL_DATE'] = carrier_data['FL_DATE'].astype('datetime64[ns]')\n",
    "carrier_data['FL_DATE'] = carrier_data.apply(lambda x: x['FL_DATE'].replace(tzinfo=timezone(x['ORIGIN_TIMEZONE'])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Next, we convert the timezone\n",
    "carrier_data['FL_DATE_UTC'] = carrier_data.apply(lambda x: x['FL_DATE'].tz_convert(pytz.utc), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Airport Congestion\n",
    "One hypothesis is that flight delays can be tied to airport \"traffic\" (or congestion). It stands to reason that if an airline has 100 flights scheduled to take off at 11am, there is a higher chance of delays than if there are only 10 flights scheduled to take off.\n",
    "\n",
    "Moreover, because traffic and delays in the morning can propegate throughout the day congestion before our flight takes off can also play a role.\n",
    "\n",
    "We'll create a set of features that put a number on this congestion.\n",
    "\n",
    "First, we will round takeoff times to the nearest hour. This will make calculations easier. Then, we will calculate average flights on a paritcular date and time, as well as the average amount of flights at different time intervals (1 hour before take off, 3 hours before takeoff, 6 hours before takeoff, 12 hours before takeoff and 24 hours before takeoff)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def takeoff_hour_rounder(time):\n",
    "    '''\n",
    "    Function takes in a time and returns time rounded to the \n",
    "    nearest hour by adding a timedelta hour if minute >= 30\n",
    "    '''\n",
    "    return (time.replace(second=0, microsecond=0, minute=0, hour=time.hour)\n",
    "               +timedelta(hours=time.minute//30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "carrier_data['FL_DATE_UTC'] =  pd.to_datetime(carrier_data['FL_DATE_UTC'], utc=True)\n",
    "carrier_data['FL_DATE_UTC_ROUNDED'] = carrier_data['FL_DATE_UTC'].apply(takeoff_hour_rounder)\n",
    "carrier_data['FL_DATE_UTC_ROUNDED'] =  pd.to_datetime(carrier_data['FL_DATE_UTC_ROUNDED'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Next we create a key for calculating congestion at each airport\n",
    "carrier_data['congestion-by-hour-key'] = carrier_data['ORIGIN'] \\\n",
    "                        + carrier_data['FL_DATE_UTC_ROUNDED'].dt.month.astype(str) \\\n",
    "                        + carrier_data['FL_DATE_UTC_ROUNDED'].dt.day.astype(str) \\\n",
    "                        + carrier_data['FL_DATE_UTC_ROUNDED'].dt.hour.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now we create a new dataframe that holds data on congestion\n",
    "airport_congestion_by_hour = carrier_data.groupby('congestion-by-hour-key')['TAIL_NUM'].count()\n",
    "airport_congestion_by_hour = airport_congestion_by_hour.to_frame()\n",
    "airport_congestion_by_hour.reset_index(inplace=True)\n",
    "airport_congestion_by_hour.rename(columns={'TAIL_NUM': 'count_of_flights'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Because we are counting by multiple years, we also create a dataframe\n",
    "# that shows how many years are in our data to calculate an average\n",
    "years_covered = carrier_data.groupby('congestion-by-hour-key')['YEAR'].nunique()\n",
    "years_covered = years_covered.to_frame()\n",
    "years_covered.reset_index(inplace=True)\n",
    "years_covered.rename(columns={'YEAR': 'years_covered'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "carrier_data['FL_DATE_UTC_ROUNDED_Tminus_1'] = carrier_data['FL_DATE_UTC_ROUNDED'] - timedelta(hours=1, minutes=0)\n",
    "carrier_data['FL_DATE_UTC_ROUNDED_Tminus_2'] = carrier_data['FL_DATE_UTC_ROUNDED'] - timedelta(hours=2, minutes=0)\n",
    "carrier_data['FL_DATE_UTC_ROUNDED_Tminus_3'] = carrier_data['FL_DATE_UTC_ROUNDED'] - timedelta(hours=3, minutes=0)\n",
    "carrier_data['FL_DATE_UTC_ROUNDED_Tminus_4'] = carrier_data['FL_DATE_UTC_ROUNDED'] - timedelta(hours=4, minutes=0)\n",
    "carrier_data['FL_DATE_UTC_ROUNDED_Tminus_5'] = carrier_data['FL_DATE_UTC_ROUNDED'] - timedelta(hours=5, minutes=0)\n",
    "carrier_data['FL_DATE_UTC_ROUNDED_Tminus_6'] = carrier_data['FL_DATE_UTC_ROUNDED'] - timedelta(hours=6, minutes=0)\n",
    "carrier_data['FL_DATE_UTC_ROUNDED_Tminus_7'] = carrier_data['FL_DATE_UTC_ROUNDED'] - timedelta(hours=7, minutes=0)\n",
    "carrier_data['FL_DATE_UTC_ROUNDED_Tminus_8'] = carrier_data['FL_DATE_UTC_ROUNDED'] - timedelta(hours=8, minutes=0)\n",
    "carrier_data['FL_DATE_UTC_ROUNDED_Tminus_9'] = carrier_data['FL_DATE_UTC_ROUNDED'] - timedelta(hours=9, minutes=0)\n",
    "carrier_data['FL_DATE_UTC_ROUNDED_Tminus_10'] = carrier_data['FL_DATE_UTC_ROUNDED'] - timedelta(hours=10, minutes=0)\n",
    "carrier_data['FL_DATE_UTC_ROUNDED_Tminus_11'] = carrier_data['FL_DATE_UTC_ROUNDED'] - timedelta(hours=11, minutes=0)\n",
    "carrier_data['FL_DATE_UTC_ROUNDED_Tminus_12'] = carrier_data['FL_DATE_UTC_ROUNDED'] - timedelta(hours=12, minutes=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "carrier_data['FL_DATE_UTC_ROUNDED_Tminus_1_key'] = carrier_data['ORIGIN'] \\\n",
    "                        + carrier_data['FL_DATE_UTC_ROUNDED_Tminus_1'].dt.month.astype(str) \\\n",
    "                        + carrier_data['FL_DATE_UTC_ROUNDED_Tminus_1'].dt.day.astype(str) \\\n",
    "                        + carrier_data['FL_DATE_UTC_ROUNDED_Tminus_1'].dt.hour.astype(str)\n",
    "carrier_data['FL_DATE_UTC_ROUNDED_Tminus_2_key'] = carrier_data['ORIGIN'] \\\n",
    "                        + carrier_data['FL_DATE_UTC_ROUNDED_Tminus_2'].dt.month.astype(str) \\\n",
    "                        + carrier_data['FL_DATE_UTC_ROUNDED_Tminus_2'].dt.day.astype(str) \\\n",
    "                        + carrier_data['FL_DATE_UTC_ROUNDED_Tminus_2'].dt.hour.astype(str)\n",
    "carrier_data['FL_DATE_UTC_ROUNDED_Tminus_3_key'] = carrier_data['ORIGIN'] \\\n",
    "                        + carrier_data['FL_DATE_UTC_ROUNDED_Tminus_3'].dt.month.astype(str) \\\n",
    "                        + carrier_data['FL_DATE_UTC_ROUNDED_Tminus_3'].dt.day.astype(str) \\\n",
    "                        + carrier_data['FL_DATE_UTC_ROUNDED_Tminus_3'].dt.hour.astype(str)\n",
    "carrier_data['FL_DATE_UTC_ROUNDED_Tminus_4_key'] = carrier_data['ORIGIN'] \\\n",
    "                        + carrier_data['FL_DATE_UTC_ROUNDED_Tminus_4'].dt.month.astype(str) \\\n",
    "                        + carrier_data['FL_DATE_UTC_ROUNDED_Tminus_4'].dt.day.astype(str) \\\n",
    "                        + carrier_data['FL_DATE_UTC_ROUNDED_Tminus_4'].dt.hour.astype(str)\n",
    "carrier_data['FL_DATE_UTC_ROUNDED_Tminus_5_key'] = carrier_data['ORIGIN'] \\\n",
    "                        + carrier_data['FL_DATE_UTC_ROUNDED_Tminus_5'].dt.month.astype(str) \\\n",
    "                        + carrier_data['FL_DATE_UTC_ROUNDED_Tminus_5'].dt.day.astype(str) \\\n",
    "                        + carrier_data['FL_DATE_UTC_ROUNDED_Tminus_5'].dt.hour.astype(str)\n",
    "carrier_data['FL_DATE_UTC_ROUNDED_Tminus_6_key'] = carrier_data['ORIGIN'] \\\n",
    "                        + carrier_data['FL_DATE_UTC_ROUNDED_Tminus_6'].dt.month.astype(str) \\\n",
    "                        + carrier_data['FL_DATE_UTC_ROUNDED_Tminus_6'].dt.day.astype(str) \\\n",
    "                        + carrier_data['FL_DATE_UTC_ROUNDED_Tminus_6'].dt.hour.astype(str)\n",
    "carrier_data['FL_DATE_UTC_ROUNDED_Tminus_7_key'] = carrier_data['ORIGIN'] \\\n",
    "                        + carrier_data['FL_DATE_UTC_ROUNDED_Tminus_7'].dt.month.astype(str) \\\n",
    "                        + carrier_data['FL_DATE_UTC_ROUNDED_Tminus_7'].dt.day.astype(str) \\\n",
    "                        + carrier_data['FL_DATE_UTC_ROUNDED_Tminus_7'].dt.hour.astype(str)\n",
    "carrier_data['FL_DATE_UTC_ROUNDED_Tminus_8_key'] = carrier_data['ORIGIN'] \\\n",
    "                        + carrier_data['FL_DATE_UTC_ROUNDED_Tminus_8'].dt.month.astype(str) \\\n",
    "                        + carrier_data['FL_DATE_UTC_ROUNDED_Tminus_8'].dt.day.astype(str) \\\n",
    "                        + carrier_data['FL_DATE_UTC_ROUNDED_Tminus_8'].dt.hour.astype(str)\n",
    "carrier_data['FL_DATE_UTC_ROUNDED_Tminus_9_key'] = carrier_data['ORIGIN'] \\\n",
    "                        + carrier_data['FL_DATE_UTC_ROUNDED_Tminus_9'].dt.month.astype(str) \\\n",
    "                        + carrier_data['FL_DATE_UTC_ROUNDED_Tminus_9'].dt.day.astype(str) \\\n",
    "                        + carrier_data['FL_DATE_UTC_ROUNDED_Tminus_9'].dt.hour.astype(str)\n",
    "carrier_data['FL_DATE_UTC_ROUNDED_Tminus_10_key'] = carrier_data['ORIGIN'] \\\n",
    "                        + carrier_data['FL_DATE_UTC_ROUNDED_Tminus_10'].dt.month.astype(str) \\\n",
    "                        + carrier_data['FL_DATE_UTC_ROUNDED_Tminus_10'].dt.day.astype(str) \\\n",
    "                        + carrier_data['FL_DATE_UTC_ROUNDED_Tminus_10'].dt.hour.astype(str)\n",
    "carrier_data['FL_DATE_UTC_ROUNDED_Tminus_11_key'] = carrier_data['ORIGIN'] \\\n",
    "                        + carrier_data['FL_DATE_UTC_ROUNDED_Tminus_11'].dt.month.astype(str) \\\n",
    "                        + carrier_data['FL_DATE_UTC_ROUNDED_Tminus_11'].dt.day.astype(str) \\\n",
    "                        + carrier_data['FL_DATE_UTC_ROUNDED_Tminus_11'].dt.hour.astype(str)\n",
    "carrier_data['FL_DATE_UTC_ROUNDED_Tminus_12_key'] = carrier_data['ORIGIN'] \\\n",
    "                        + carrier_data['FL_DATE_UTC_ROUNDED_Tminus_12'].dt.month.astype(str) \\\n",
    "                        + carrier_data['FL_DATE_UTC_ROUNDED_Tminus_12'].dt.day.astype(str) \\\n",
    "                        + carrier_data['FL_DATE_UTC_ROUNDED_Tminus_12'].dt.hour.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We won't be using the rounded times again, so it's good to just drop those columns for the sake of memory\n",
    "carrier_data.drop(columns=['FL_DATE_UTC_ROUNDED', 'FL_DATE_UTC_ROUNDED_Tminus_1', 'FL_DATE_UTC_ROUNDED_Tminus_2',\n",
    "                 'FL_DATE_UTC_ROUNDED_Tminus_3', 'FL_DATE_UTC_ROUNDED_Tminus_4',\n",
    "                 'FL_DATE_UTC_ROUNDED_Tminus_5', 'FL_DATE_UTC_ROUNDED_Tminus_6',\n",
    "                 'FL_DATE_UTC_ROUNDED_Tminus_7', 'FL_DATE_UTC_ROUNDED_Tminus_8',\n",
    "                 'FL_DATE_UTC_ROUNDED_Tminus_9', 'FL_DATE_UTC_ROUNDED_Tminus_10',\n",
    "                 'FL_DATE_UTC_ROUNDED_Tminus_11', 'FL_DATE_UTC_ROUNDED_Tminus_12'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "carrier_data['CONGESTION_TMINUS_0'] = carrier_data['congestion-by-hour-key'].map(airport_congestion_by_hour.set_index('congestion-by-hour-key')['count_of_flights'])\n",
    "airport_congestion_by_hour.columns = airport_congestion_by_hour.columns.str.replace(\"congestion-by-hour-key\", \"FL_DATE_UTC_ROUNDED_Tminus_1_key\")\n",
    "carrier_data['CONGESTION_TMINUS_1'] = carrier_data['FL_DATE_UTC_ROUNDED_Tminus_1_key'].map(airport_congestion_by_hour.set_index('FL_DATE_UTC_ROUNDED_Tminus_1_key')['count_of_flights'])\n",
    "airport_congestion_by_hour.columns = airport_congestion_by_hour.columns.str.replace(\"FL_DATE_UTC_ROUNDED_Tminus_1_key\", \"FL_DATE_UTC_ROUNDED_Tminus_2_key\")\n",
    "carrier_data['CONGESTION_TMINUS_2'] = carrier_data['FL_DATE_UTC_ROUNDED_Tminus_2_key'].map(airport_congestion_by_hour.set_index('FL_DATE_UTC_ROUNDED_Tminus_2_key')['count_of_flights'])\n",
    "airport_congestion_by_hour.columns = airport_congestion_by_hour.columns.str.replace(\"FL_DATE_UTC_ROUNDED_Tminus_2_key\", \"FL_DATE_UTC_ROUNDED_Tminus_3_key\")\n",
    "carrier_data['CONGESTION_TMINUS_3'] = carrier_data['FL_DATE_UTC_ROUNDED_Tminus_3_key'].map(airport_congestion_by_hour.set_index('FL_DATE_UTC_ROUNDED_Tminus_3_key')['count_of_flights'])\n",
    "airport_congestion_by_hour.columns = airport_congestion_by_hour.columns.str.replace(\"FL_DATE_UTC_ROUNDED_Tminus_3_key\", \"FL_DATE_UTC_ROUNDED_Tminus_4_key\")\n",
    "carrier_data['CONGESTION_TMINUS_4'] = carrier_data['FL_DATE_UTC_ROUNDED_Tminus_4_key'].map(airport_congestion_by_hour.set_index('FL_DATE_UTC_ROUNDED_Tminus_4_key')['count_of_flights'])\n",
    "airport_congestion_by_hour.columns = airport_congestion_by_hour.columns.str.replace(\"FL_DATE_UTC_ROUNDED_Tminus_4_key\", \"FL_DATE_UTC_ROUNDED_Tminus_5_key\")\n",
    "carrier_data['CONGESTION_TMINUS_5'] = carrier_data['FL_DATE_UTC_ROUNDED_Tminus_5_key'].map(airport_congestion_by_hour.set_index('FL_DATE_UTC_ROUNDED_Tminus_5_key')['count_of_flights'])\n",
    "airport_congestion_by_hour.columns = airport_congestion_by_hour.columns.str.replace(\"FL_DATE_UTC_ROUNDED_Tminus_5_key\", \"FL_DATE_UTC_ROUNDED_Tminus_6_key\")\n",
    "carrier_data['CONGESTION_TMINUS_6'] = carrier_data['FL_DATE_UTC_ROUNDED_Tminus_6_key'].map(airport_congestion_by_hour.set_index('FL_DATE_UTC_ROUNDED_Tminus_6_key')['count_of_flights'])\n",
    "airport_congestion_by_hour.columns = airport_congestion_by_hour.columns.str.replace(\"FL_DATE_UTC_ROUNDED_Tminus_6_key\", \"FL_DATE_UTC_ROUNDED_Tminus_7_key\")\n",
    "carrier_data['CONGESTION_TMINUS_7'] = carrier_data['FL_DATE_UTC_ROUNDED_Tminus_7_key'].map(airport_congestion_by_hour.set_index('FL_DATE_UTC_ROUNDED_Tminus_7_key')['count_of_flights'])\n",
    "airport_congestion_by_hour.columns = airport_congestion_by_hour.columns.str.replace(\"FL_DATE_UTC_ROUNDED_Tminus_7_key\", \"FL_DATE_UTC_ROUNDED_Tminus_8_key\")\n",
    "carrier_data['CONGESTION_TMINUS_8'] = carrier_data['FL_DATE_UTC_ROUNDED_Tminus_8_key'].map(airport_congestion_by_hour.set_index('FL_DATE_UTC_ROUNDED_Tminus_8_key')['count_of_flights'])\n",
    "airport_congestion_by_hour.columns = airport_congestion_by_hour.columns.str.replace(\"FL_DATE_UTC_ROUNDED_Tminus_8_key\", \"FL_DATE_UTC_ROUNDED_Tminus_9_key\")\n",
    "carrier_data['CONGESTION_TMINUS_9'] = carrier_data['FL_DATE_UTC_ROUNDED_Tminus_9_key'].map(airport_congestion_by_hour.set_index('FL_DATE_UTC_ROUNDED_Tminus_9_key')['count_of_flights'])\n",
    "airport_congestion_by_hour.columns = airport_congestion_by_hour.columns.str.replace(\"FL_DATE_UTC_ROUNDED_Tminus_9_key\", \"FL_DATE_UTC_ROUNDED_Tminus_10_key\")\n",
    "carrier_data['CONGESTION_TMINUS_10'] = carrier_data['FL_DATE_UTC_ROUNDED_Tminus_10_key'].map(airport_congestion_by_hour.set_index('FL_DATE_UTC_ROUNDED_Tminus_10_key')['count_of_flights'])\n",
    "airport_congestion_by_hour.columns = airport_congestion_by_hour.columns.str.replace(\"FL_DATE_UTC_ROUNDED_Tminus_10_key\", \"FL_DATE_UTC_ROUNDED_Tminus_11_key\")\n",
    "carrier_data['CONGESTION_TMINUS_11'] = carrier_data['FL_DATE_UTC_ROUNDED_Tminus_11_key'].map(airport_congestion_by_hour.set_index('FL_DATE_UTC_ROUNDED_Tminus_11_key')['count_of_flights'])\n",
    "airport_congestion_by_hour.columns = airport_congestion_by_hour.columns.str.replace(\"FL_DATE_UTC_ROUNDED_Tminus_11_key\", \"FL_DATE_UTC_ROUNDED_Tminus_12_key\")\n",
    "carrier_data['CONGESTION_TMINUS_12'] = carrier_data['FL_DATE_UTC_ROUNDED_Tminus_12_key'].map(airport_congestion_by_hour.set_index('FL_DATE_UTC_ROUNDED_Tminus_12_key')['count_of_flights'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "carrier_data['years_covered'] = carrier_data['congestion-by-hour-key'].map(years_covered.set_index('congestion-by-hour-key')['years_covered'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "carrier_data['CONGESTION_TMINUS_0'] = carrier_data['CONGESTION_TMINUS_0'].fillna(0)\n",
    "carrier_data['CONGESTION_TMINUS_1'] = carrier_data['CONGESTION_TMINUS_1'].fillna(0)\n",
    "carrier_data['CONGESTION_TMINUS_2'] = carrier_data['CONGESTION_TMINUS_2'].fillna(0)\n",
    "carrier_data['CONGESTION_TMINUS_3'] = carrier_data['CONGESTION_TMINUS_3'].fillna(0)\n",
    "carrier_data['CONGESTION_TMINUS_4'] = carrier_data['CONGESTION_TMINUS_4'].fillna(0)\n",
    "carrier_data['CONGESTION_TMINUS_5'] = carrier_data['CONGESTION_TMINUS_5'].fillna(0)\n",
    "carrier_data['CONGESTION_TMINUS_6'] = carrier_data['CONGESTION_TMINUS_6'].fillna(0)\n",
    "carrier_data['CONGESTION_TMINUS_7'] = carrier_data['CONGESTION_TMINUS_7'].fillna(0)\n",
    "carrier_data['CONGESTION_TMINUS_8'] = carrier_data['CONGESTION_TMINUS_8'].fillna(0)\n",
    "carrier_data['CONGESTION_TMINUS_9'] = carrier_data['CONGESTION_TMINUS_9'].fillna(0)\n",
    "carrier_data['CONGESTION_TMINUS_10'] = carrier_data['CONGESTION_TMINUS_10'].fillna(0)\n",
    "carrier_data['CONGESTION_TMINUS_11'] = carrier_data['CONGESTION_TMINUS_11'].fillna(0)\n",
    "carrier_data['CONGESTION_TMINUS_12'] = carrier_data['CONGESTION_TMINUS_12'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We won't be using the these keys again, so it's good to just drop those columns for the sake of memory\n",
    "carrier_data.drop(columns=['congestion-by-hour-key', 'FL_DATE_UTC_ROUNDED_Tminus_1_key', 'FL_DATE_UTC_ROUNDED_Tminus_2_key',\n",
    "                 'FL_DATE_UTC_ROUNDED_Tminus_3_key', 'FL_DATE_UTC_ROUNDED_Tminus_4_key',\n",
    "                 'FL_DATE_UTC_ROUNDED_Tminus_5_key', 'FL_DATE_UTC_ROUNDED_Tminus_6_key',\n",
    "                 'FL_DATE_UTC_ROUNDED_Tminus_7_key', 'FL_DATE_UTC_ROUNDED_Tminus_8_key',\n",
    "                 'FL_DATE_UTC_ROUNDED_Tminus_9_key', 'FL_DATE_UTC_ROUNDED_Tminus_10_key',\n",
    "                 'FL_DATE_UTC_ROUNDED_Tminus_11_key', 'FL_DATE_UTC_ROUNDED_Tminus_12_key'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "carrier_data['CONGESTION_TMINUS_0-3'] = carrier_data['CONGESTION_TMINUS_0'] \\\n",
    "                                    + carrier_data['CONGESTION_TMINUS_1'] \\\n",
    "                                    + carrier_data['CONGESTION_TMINUS_2'] \\\n",
    "                                    + carrier_data['CONGESTION_TMINUS_3'] \n",
    "\n",
    "carrier_data['CONGESTION_TMINUS_0-6'] = carrier_data['CONGESTION_TMINUS_0'] \\\n",
    "                                    + carrier_data['CONGESTION_TMINUS_1'] \\\n",
    "                                    + carrier_data['CONGESTION_TMINUS_2'] \\\n",
    "                                    + carrier_data['CONGESTION_TMINUS_3'] \\\n",
    "                                    + carrier_data['CONGESTION_TMINUS_4'] \\\n",
    "                                    + carrier_data['CONGESTION_TMINUS_5'] \\\n",
    "                                    + carrier_data['CONGESTION_TMINUS_6']\n",
    "\n",
    "carrier_data['CONGESTION_TMINUS_0-12'] = carrier_data['CONGESTION_TMINUS_0'] \\\n",
    "                                    + carrier_data['CONGESTION_TMINUS_1'] \\\n",
    "                                    + carrier_data['CONGESTION_TMINUS_2'] \\\n",
    "                                    + carrier_data['CONGESTION_TMINUS_3'] \\\n",
    "                                    + carrier_data['CONGESTION_TMINUS_4'] \\\n",
    "                                    + carrier_data['CONGESTION_TMINUS_5'] \\\n",
    "                                    + carrier_data['CONGESTION_TMINUS_6'] \\\n",
    "                                    + carrier_data['CONGESTION_TMINUS_7'] \\\n",
    "                                    + carrier_data['CONGESTION_TMINUS_8'] \\\n",
    "                                    + carrier_data['CONGESTION_TMINUS_9'] \\\n",
    "                                    + carrier_data['CONGESTION_TMINUS_10'] \\\n",
    "                                    + carrier_data['CONGESTION_TMINUS_11'] \\\n",
    "                                    + carrier_data['CONGESTION_TMINUS_12']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "carrier_data['AVG_CONGESTION_TMINUS_0'] = carrier_data['CONGESTION_TMINUS_0'] / carrier_data['years_covered']\n",
    "carrier_data['AVG_CONGESTION_TMINUS_0-3'] = carrier_data['CONGESTION_TMINUS_0-3'] / carrier_data['years_covered']\n",
    "carrier_data['AVG_CONGESTION_TMINUS_0-6'] = carrier_data['CONGESTION_TMINUS_0-6'] / carrier_data['years_covered']\n",
    "carrier_data['AVG_CONGESTION_TMINUS_0-12'] = carrier_data['CONGESTION_TMINUS_0-12'] / carrier_data['years_covered']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Again let's drop columns we won't need\n",
    "carrier_data.drop(columns=['CONGESTION_TMINUS_0', 'CONGESTION_TMINUS_1', 'CONGESTION_TMINUS_2',\n",
    "                          'CONGESTION_TMINUS_3', 'CONGESTION_TMINUS_4', 'CONGESTION_TMINUS_5',\n",
    "                          'CONGESTION_TMINUS_6', 'CONGESTION_TMINUS_7', 'CONGESTION_TMINUS_8',\n",
    "                          'CONGESTION_TMINUS_9', 'CONGESTION_TMINUS_10', 'CONGESTION_TMINUS_11', \n",
    "                          'CONGESTION_TMINUS_12', 'CONGESTION_TMINUS_0-3', 'CONGESTION_TMINUS_0-6',\n",
    "                          'CONGESTION_TMINUS_0-12', 'years_covered'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering for Airports & Airlines Relevant to Business Case\n",
    "The MVP calls for us to support flights originating from major US airports and 8 major airlines. So we filter down our data for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create list of relevant aiports based on business case\n",
    "relevant_airports = ['ATL', 'DFW', 'DEN', 'ORD', 'LAX', 'CLT', 'LAS', 'PHX', \n",
    "                     'MCO', 'SEA', 'MIA', 'IAH', 'JFK', 'FLL', 'EWR', 'SFO', 'MSP', 'DTW',\n",
    "                     'BOS', 'SLC', 'PHL', 'BWI', 'TPA', 'SAN', 'MDW', 'LGA', 'BNA', 'IAD',\n",
    "                     'DAL', 'DCA', 'PDX', 'AUS', 'HOU', 'HNL', 'STL', 'RSW', 'SMF', 'MSY',\n",
    "                     'SJU', 'RDU', 'OAK', 'MCI', 'CLE', 'IND', 'SAT', 'SNA', 'PIT', 'CVG',\n",
    "                     'CMH', 'PBI', 'JAX', 'MKE', 'ONT', 'ANC', 'BDL', 'OGG', 'OMA', 'MEM',\n",
    "                     'BOI', 'RNO', 'CHS', 'OKC']\n",
    "\n",
    "# Create list of relevant IATA airline designators based on business case\n",
    "relevant_airlines = ['WN', # Southwest\n",
    "                     'DL', # Delta\n",
    "                     'OO', # SkyWest\n",
    "                     'AA', # American Airlines\n",
    "                     'UA', # United Airlines\n",
    "                     'B6', # JetBlue\n",
    "                     'AS', # Alaska Airlines\n",
    "                     'NK', # Spirit Airlines\n",
    "                    ]\n",
    "\n",
    "# Filter Dataframe to include only relevant airlines & airports\n",
    "airport_filter = '|'.join(relevant_airports)\n",
    "airline_filter = '|'.join(relevant_airlines)\n",
    "\n",
    "carrier_data = carrier_data[carrier_data['ORIGIN'].str.contains(airport_filter)]\n",
    "carrier_data = carrier_data[carrier_data['OP_CARRIER'].str.contains(airline_filter)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mering in Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Robert\\anaconda3\\envs\\learn-env\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3145: DtypeWarning: Columns (13,25,31,43,45,49,55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "# Importing weather station data\n",
    "weather_df = pd.read_csv('data/downloaded/weather-data.csv')\n",
    "\n",
    "# Importing data that maps each airport to a weather station\n",
    "stations_airport_df = pd.read_csv('data/downloaded/weather-station-codes-airport-key.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# First, we need to add the Weather Station ID for each airport in our dataset\n",
    "carrier_data['weather_station_origin'] = carrier_data['ORIGIN'].map(stations_airport_df.set_index('airport_code')['noaa_station'])\n",
    "carrier_data['weather_station_destination'] = carrier_data['DEST'].map(stations_airport_df.set_index('airport_code')['noaa_station'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We only care about certain fields in our weather dataframe so we filter for those\n",
    "relevant_weather_cols = [\n",
    "'STATION',\n",
    "'DATE',\n",
    "'LATITUDE',\n",
    "'LONGITUDE',\n",
    "'AWND',\n",
    "'PRCP',\n",
    "'SNOW',\n",
    "'TMIN',\n",
    "'TMAX',\n",
    "'ELEVATION',\n",
    "'SNWD',\n",
    "'WDF2',\n",
    "'WSF2',\n",
    "'WT01',\n",
    "'WT02',\n",
    "'WT03',\n",
    "'WT04',\n",
    "'WT06',\n",
    "'WT08'\n",
    "]\n",
    "\n",
    "weather_df = weather_df[relevant_weather_cols].copy()\n",
    "weather_df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a key to prepare merging in daily weather data for each airport\n",
    "weather_df['key'] = weather_df[\"STATION\"].astype(str) + weather_df[\"DATE\"].astype(str)\n",
    "carrier_data['key'] = carrier_data['weather_station_origin'] + carrier_data['YEAR'].astype(str) + '/' + carrier_data['MONTH'].astype(str).str.zfill(2) + '/' + carrier_data['DAY_OF_MONTH'].astype(str).str.zfill(2)\n",
    "carrier_data = carrier_data.merge(weather_df, on='key')\n",
    "weather_df = weather_df.add_prefix('dest_')\n",
    "carrier_data['dest_key'] = carrier_data['weather_station_destination'] + carrier_data['YEAR'].astype(str) + '/' + carrier_data['MONTH'].astype(str).str.zfill(2) + '/' + carrier_data['DAY_OF_MONTH'].astype(str).str.zfill(2)\n",
    "carrier_data = carrier_data.merge(weather_df, on='dest_key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Once again, we clean up columns we don't need anymore\n",
    "carrier_data.drop(columns=['key', 'dest_key', 'weather_station_origin', 'weather_station_destination',\n",
    "                          'STATION', 'dest_STATION', 'DATE', 'dest_DATE', 'dest_LATITUDE', 'dest_LONGITUDE',\n",
    "                          'LATITUDE', 'LONGITUDE'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Proximity to Holidays\n",
    "Anyone who has ever traveled by plane knows that delays seem to be most prevelant around the holidays. That's why one last feature we want to engineer is some sort of proximity to holidays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pandas.tseries.holiday import USFederalHolidayCalendar as calendar\n",
    "\n",
    "date_range = pd.date_range(start='2018-01-01', end='2021-12-31')\n",
    "cal = calendar()\n",
    "holidays = cal.holidays(start=date_range.min(), end=date_range.max(), return_name=True)\n",
    "holidays.reset_index(name='holiday').rename(columns={'index':'date'})\n",
    "holidays = holidays.to_frame()\n",
    "holidays.reset_index(inplace=True)\n",
    "holidays.columns = ['holiday_date', 'holiday_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>holiday_date</th>\n",
       "      <th>holiday_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>New Years Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-15</td>\n",
       "      <td>Martin Luther King Jr. Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-02-19</td>\n",
       "      <td>Presidents Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-05-28</td>\n",
       "      <td>Memorial Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-07-04</td>\n",
       "      <td>July 4th</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018-09-03</td>\n",
       "      <td>Labor Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2018-10-08</td>\n",
       "      <td>Columbus Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2018-11-12</td>\n",
       "      <td>Veterans Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2018-11-22</td>\n",
       "      <td>Thanksgiving</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2018-12-25</td>\n",
       "      <td>Christmas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>New Years Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2019-01-21</td>\n",
       "      <td>Martin Luther King Jr. Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2019-02-18</td>\n",
       "      <td>Presidents Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2019-05-27</td>\n",
       "      <td>Memorial Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2019-07-04</td>\n",
       "      <td>July 4th</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2019-09-02</td>\n",
       "      <td>Labor Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2019-10-14</td>\n",
       "      <td>Columbus Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2019-11-11</td>\n",
       "      <td>Veterans Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2019-11-28</td>\n",
       "      <td>Thanksgiving</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2019-12-25</td>\n",
       "      <td>Christmas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>New Years Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2020-01-20</td>\n",
       "      <td>Martin Luther King Jr. Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2020-02-17</td>\n",
       "      <td>Presidents Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2020-05-25</td>\n",
       "      <td>Memorial Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2020-07-03</td>\n",
       "      <td>July 4th</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2020-09-07</td>\n",
       "      <td>Labor Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2020-10-12</td>\n",
       "      <td>Columbus Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2020-11-11</td>\n",
       "      <td>Veterans Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2020-11-26</td>\n",
       "      <td>Thanksgiving</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2020-12-25</td>\n",
       "      <td>Christmas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>New Years Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2021-01-18</td>\n",
       "      <td>Martin Luther King Jr. Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2021-02-15</td>\n",
       "      <td>Presidents Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2021-05-31</td>\n",
       "      <td>Memorial Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2021-07-05</td>\n",
       "      <td>July 4th</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2021-09-06</td>\n",
       "      <td>Labor Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2021-10-11</td>\n",
       "      <td>Columbus Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2021-11-11</td>\n",
       "      <td>Veterans Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2021-11-25</td>\n",
       "      <td>Thanksgiving</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2021-12-24</td>\n",
       "      <td>Christmas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>New Years Day</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   holiday_date                holiday_name\n",
       "0    2018-01-01               New Years Day\n",
       "1    2018-01-15  Martin Luther King Jr. Day\n",
       "2    2018-02-19              Presidents Day\n",
       "3    2018-05-28                Memorial Day\n",
       "4    2018-07-04                    July 4th\n",
       "5    2018-09-03                   Labor Day\n",
       "6    2018-10-08                Columbus Day\n",
       "7    2018-11-12                Veterans Day\n",
       "8    2018-11-22                Thanksgiving\n",
       "9    2018-12-25                   Christmas\n",
       "10   2019-01-01               New Years Day\n",
       "11   2019-01-21  Martin Luther King Jr. Day\n",
       "12   2019-02-18              Presidents Day\n",
       "13   2019-05-27                Memorial Day\n",
       "14   2019-07-04                    July 4th\n",
       "15   2019-09-02                   Labor Day\n",
       "16   2019-10-14                Columbus Day\n",
       "17   2019-11-11                Veterans Day\n",
       "18   2019-11-28                Thanksgiving\n",
       "19   2019-12-25                   Christmas\n",
       "20   2020-01-01               New Years Day\n",
       "21   2020-01-20  Martin Luther King Jr. Day\n",
       "22   2020-02-17              Presidents Day\n",
       "23   2020-05-25                Memorial Day\n",
       "24   2020-07-03                    July 4th\n",
       "25   2020-09-07                   Labor Day\n",
       "26   2020-10-12                Columbus Day\n",
       "27   2020-11-11                Veterans Day\n",
       "28   2020-11-26                Thanksgiving\n",
       "29   2020-12-25                   Christmas\n",
       "30   2021-01-01               New Years Day\n",
       "31   2021-01-18  Martin Luther King Jr. Day\n",
       "32   2021-02-15              Presidents Day\n",
       "33   2021-05-31                Memorial Day\n",
       "34   2021-07-05                    July 4th\n",
       "35   2021-09-06                   Labor Day\n",
       "36   2021-10-11                Columbus Day\n",
       "37   2021-11-11                Veterans Day\n",
       "38   2021-11-25                Thanksgiving\n",
       "39   2021-12-24                   Christmas\n",
       "40   2021-12-31               New Years Day"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "carrier_data['holiday-key'] = carrier_data['YEAR'].astype(str) + '-' + carrier_data['MONTH'].astype(str).str.zfill(2) + '-' + carrier_data['DAY_OF_MONTH'].astype(str).str.zfill(2)\n",
    "carrier_data['holiday-key'] = pd.to_datetime(carrier_data['holiday-key'])\n",
    "carrier_data.sort_values('holiday-key', inplace=True)\n",
    "carrier_data = pd.merge_asof(carrier_data, holidays, left_on='holiday-key', right_on='holiday_date',\n",
    "                       direction='nearest', tolerance=pd.Timedelta(days=7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "carrier_data['days-from-holiday'] = (carrier_data['holiday-key'] - carrier_data['holiday_date']).dt.days\n",
    "carrier_data['days-from-holiday'] = carrier_data['days-from-holiday'].astype(str)\n",
    "carrier_data['days-from-specific-holiday'] = carrier_data['holiday_name'] + '_' + carrier_data['days-from-holiday'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Cleaning up the results a bit\n",
    "carrier_data['days-from-specific-holiday'].fillna('no-close-holiday', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Once again, we clean up columns we don't need anymore\n",
    "carrier_data.drop(columns=['holiday-key', 'holiday_name', 'holiday_date', 'days-from-holiday', 'days-from-holiday'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time of day takoff & landing\n",
    "Lastly, we will create a continuous variable that quantifies when throughout the day that flight takes off. This is to account that it's possible for delays to be more prevalent at certain points in the day. To do this, we'll create a variable that measures a flight's distance from midnight in minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "carrier_data['temp_time'] = pd.to_datetime(carrier_data['CRS_DEP_TIME'])\n",
    "carrier_data['takeoff-mins-from-midnight'] = ((carrier_data['temp_time'] - carrier_data['temp_time'].dt.normalize()) / pd.Timedelta('1 minute')).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "carrier_data['CRS_ARR_TIME'] = carrier_data['CRS_ARR_TIME'].apply(float_to_time)\n",
    "carrier_data['CRS_ARR_TIME'] = carrier_data['CRS_ARR_TIME'].replace({'24:00':'00:00'})\n",
    "carrier_data['temp_time_dest'] = pd.to_datetime(carrier_data['CRS_ARR_TIME'], format='%H:%M')\n",
    "carrier_data['landing-mins-from-midnight'] = ((carrier_data['temp_time_dest'] - carrier_data['temp_time_dest'].dt.normalize()) / pd.Timedelta('1 minute')).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "carrier_data.drop(columns=['temp_time', 'temp_time_dest'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping Irrelevant Columns\n",
    "Our downloaded data has a lof of columns. We won't need many of them for our analysis. So here we drop remaining irrelevant columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cols_to_drop = ['QUARTER',\n",
    "'FL_DATE',\n",
    "'OP_UNIQUE_CARRIER',\n",
    "'TAIL_NUM',\n",
    "'DEST_AIRPORT_ID',\n",
    "'CRS_DEP_TIME',\n",
    "'DEP_TIME',\n",
    "'TAXI_OUT',\n",
    "'WHEELS_OFF',\n",
    "'TAXI_IN',\n",
    "'CRS_ARR_TIME',\n",
    "'ARR_TIME',\n",
    "'ARR_DELAY',\n",
    "'CANCELLATION_CODE',\n",
    "'DIVERTED',\n",
    "'ACTUAL_ELAPSED_TIME',\n",
    "'AIR_TIME',\n",
    "'FLIGHTS',\n",
    "'FIRST_DEP_TIME',\n",
    "'TOTAL_ADD_GTIME',\n",
    "'LONGEST_ADD_GTIME',\n",
    "'ORIGIN_TIMEZONE',\n",
    "'FL_DATE_UTC']\n",
    "\n",
    "carrier_data.drop(cols_to_drop, axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning up missing data\n",
    "As a last step, I'll deal with any missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YEAR                                 0\n",
       "WDF2                                 0\n",
       "WSF2                                 0\n",
       "WT01                                 0\n",
       "WT02                                 0\n",
       "WT03                                 0\n",
       "WT04                                 0\n",
       "WT06                                 0\n",
       "WT08                                 0\n",
       "dest_AWND                            0\n",
       "dest_PRCP                            0\n",
       "dest_SNOW                            0\n",
       "SNWD                                 0\n",
       "dest_TMIN                            0\n",
       "dest_ELEVATION                       0\n",
       "dest_SNWD                            0\n",
       "dest_WDF2                            0\n",
       "dest_WSF2                            0\n",
       "dest_WT01                            0\n",
       "dest_WT02                            0\n",
       "dest_WT03                            0\n",
       "dest_WT04                            0\n",
       "dest_WT06                            0\n",
       "dest_WT08                            0\n",
       "days-from-specific-holiday           0\n",
       "dest_TMAX                            0\n",
       "ELEVATION                            0\n",
       "TMAX                                 0\n",
       "TMIN                                 0\n",
       "MONTH                                0\n",
       "DAY_OF_MONTH                         0\n",
       "DAY_OF_WEEK                          0\n",
       "MKT_CARRIER                          0\n",
       "MKT_CARRIER_FL_NUM                   0\n",
       "OP_CARRIER                           0\n",
       "ORIGIN                               0\n",
       "DEST                                 0\n",
       "CANCELLED                            0\n",
       "takeoff-mins-from-midnight           0\n",
       "DISTANCE                             0\n",
       "AVG_CONGESTION_TMINUS_0              0\n",
       "AVG_CONGESTION_TMINUS_0-3            0\n",
       "AVG_CONGESTION_TMINUS_0-6            0\n",
       "AVG_CONGESTION_TMINUS_0-12           0\n",
       "AWND                                 0\n",
       "PRCP                                 0\n",
       "SNOW                                 0\n",
       "landing-mins-from-midnight           0\n",
       "CRS_ELAPSED_TIME                     3\n",
       "DEP_DELAY_NEW                   344419\n",
       "ARR_DELAY_NEW                   383002\n",
       "CARRIER_DELAY                 12260761\n",
       "NAS_DELAY                     12260761\n",
       "SECURITY_DELAY                12260761\n",
       "LATE_AIRCRAFT_DELAY           12260761\n",
       "WEATHER_DELAY                 12260761\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "carrier_data.isna().sum().sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, it looks like we have a few missing 'DEP_DELAY_NEW' and \"ARR_DELAY_NEW\" fields. However, these are just 0.02% of our total records. So it's easy enough to just drop those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "carrier_data = carrier_data.dropna(subset=['DEP_DELAY_NEW', 'ARR_DELAY_NEW', 'CRS_ELAPSED_TIME'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take another look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YEAR                                 0\n",
       "WDF2                                 0\n",
       "WSF2                                 0\n",
       "WT01                                 0\n",
       "WT02                                 0\n",
       "WT03                                 0\n",
       "WT04                                 0\n",
       "WT06                                 0\n",
       "WT08                                 0\n",
       "dest_AWND                            0\n",
       "dest_PRCP                            0\n",
       "dest_SNOW                            0\n",
       "SNWD                                 0\n",
       "dest_TMIN                            0\n",
       "dest_ELEVATION                       0\n",
       "dest_SNWD                            0\n",
       "dest_WDF2                            0\n",
       "dest_WSF2                            0\n",
       "dest_WT01                            0\n",
       "dest_WT02                            0\n",
       "dest_WT03                            0\n",
       "dest_WT04                            0\n",
       "dest_WT06                            0\n",
       "dest_WT08                            0\n",
       "days-from-specific-holiday           0\n",
       "dest_TMAX                            0\n",
       "ELEVATION                            0\n",
       "TMAX                                 0\n",
       "TMIN                                 0\n",
       "MONTH                                0\n",
       "DAY_OF_MONTH                         0\n",
       "DAY_OF_WEEK                          0\n",
       "MKT_CARRIER                          0\n",
       "MKT_CARRIER_FL_NUM                   0\n",
       "OP_CARRIER                           0\n",
       "ORIGIN                               0\n",
       "DEST                                 0\n",
       "DEP_DELAY_NEW                        0\n",
       "ARR_DELAY_NEW                        0\n",
       "CANCELLED                            0\n",
       "CRS_ELAPSED_TIME                     0\n",
       "DISTANCE                             0\n",
       "AVG_CONGESTION_TMINUS_0              0\n",
       "AVG_CONGESTION_TMINUS_0-3            0\n",
       "AVG_CONGESTION_TMINUS_0-6            0\n",
       "AVG_CONGESTION_TMINUS_0-12           0\n",
       "AWND                                 0\n",
       "PRCP                                 0\n",
       "SNOW                                 0\n",
       "takeoff-mins-from-midnight           0\n",
       "landing-mins-from-midnight           0\n",
       "CARRIER_DELAY                 11877759\n",
       "WEATHER_DELAY                 11877759\n",
       "NAS_DELAY                     11877759\n",
       "SECURITY_DELAY                11877759\n",
       "LATE_AIRCRAFT_DELAY           11877759\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "carrier_data.isna().sum().sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the delay cause fields (CARRIER_DELAY, WEATHER_DELAY, NAS_DELAY, SECURITY_DELAY and LATE_AIRCRAFT_DELAY) have many missing values. Lucikily, these fields are not needed for modeling so we can proceed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's remove all the extra columns that were created for the purpose of engineering these features\n",
    "cols_with_bad_data = ['CARRIER_DELAY', 'WEATHER_DELAY', 'NAS_DELAY', 'SECURITY_DELAY', 'LATE_AIRCRAFT_DELAY']\n",
    "carrier_data.drop(cols_with_bad_data, axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "carrier_data.to_csv('data/prepared/cleaned_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

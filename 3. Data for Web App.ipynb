{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flight Delays: Web App"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we'll prepare data for use in our Dash web app.\n",
    "\n",
    "### Business Goals\n",
    "\n",
    "Here we want to achieve the following:\n",
    "\n",
    "1. Prepare data for vizualizations by date\n",
    "2. Prepare data for vizualizations by airline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import plotly.express as px\n",
    "import sqlite3 as db\n",
    "import datetime\n",
    "from pytz import timezone\n",
    "import pytz\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=FutureWarning)\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix,\\\n",
    "precision_recall_fscore_support, f1_score, plot_confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV,\\\n",
    "cross_validate, cross_val_predict, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, ConfusionMatrixDisplay\n",
    "\n",
    "from keras import regularizers\n",
    "from keras import models\n",
    "from keras import layers\n",
    "import lightgbm\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=FutureWarning)\n",
    "from scipy import stats\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "carrier_data = pd.read_csv('data/prepared/data_for_graphing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_airports = ['ATL', 'DFW', 'DEN', 'ORD', 'LAX', 'CLT', 'LAS', 'PHX', \n",
    "                     'MCO', 'SEA', 'MIA', 'IAH', 'JFK', 'FLL', 'EWR', 'SFO', 'MSP', 'DTW',\n",
    "                     'BOS', 'SLC', 'PHL', 'BWI', 'TPA', 'SAN', 'MDW', 'LGA', 'BNA', 'IAD',\n",
    "                     'DAL', 'DCA', 'PDX', 'AUS', 'HOU', 'HNL', 'STL', 'RSW', 'SMF', 'MSY',\n",
    "                     'SJU', 'RDU', 'OAK', 'MCI', 'CLE', 'IND', 'SAT', 'SNA', 'PIT', 'CVG',\n",
    "                     'CMH', 'PBI', 'JAX', 'MKE', 'ONT', 'ANC', 'BDL', 'OGG', 'OMA', 'MEM',\n",
    "                     'BOI', 'RNO', 'CHS', 'OKC']\n",
    "\n",
    "airport_filter = '|'.join(relevant_airports)\n",
    "\n",
    "carrier_data = carrier_data[carrier_data['ORIGIN'].str.contains(airport_filter)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "carrier_data['airport-lookup-key'] = carrier_data['ORIGIN'] + '-' + carrier_data['DEST']\n",
    "airport_lookup = carrier_data.drop_duplicates(subset=['airport-lookup-key'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "airport_lookup = airport_lookup[['ORIGIN', 'DEST','airport-lookup-key', 'origin-elevation','dest-elevation', 'DISTANCE','dest-lat-long','origin-lat-long','origin-tz','dest-tz']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "airport_lookup.to_csv('data/prepared/airport_lookup.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping Data by Day\n",
    "\n",
    "To group by day, we'll need to create a datetime field to group by first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "carrier_data['severe_delay'] = carrier_data['ARR_DELAY_NEW'] > 60\n",
    "carrier_data['severe_delay'] = carrier_data['severe_delay'].map({True: 'Severe Delays', False: 'No Severe Delays'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "carrier_data['FL_DATE'] = pd.to_datetime(carrier_data['FL_DATE']).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data = carrier_data.groupby(['FL_DATE', 'ORIGIN', 'holiday', 'DAY_OF_WEEK', 'takeoff-time-of-day', 'severe_delay'], as_index=False).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's preview our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FL_DATE</th>\n",
       "      <th>ORIGIN</th>\n",
       "      <th>holiday</th>\n",
       "      <th>DAY_OF_WEEK</th>\n",
       "      <th>takeoff-time-of-day</th>\n",
       "      <th>severe_delay</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>ANC</td>\n",
       "      <td>Not a Holiday</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Early Afternoon</td>\n",
       "      <td>No Severe Delays</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>ANC</td>\n",
       "      <td>Not a Holiday</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Early Afternoon</td>\n",
       "      <td>Severe Delays</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>ANC</td>\n",
       "      <td>Not a Holiday</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Early Evening</td>\n",
       "      <td>No Severe Delays</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>ANC</td>\n",
       "      <td>Not a Holiday</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Early Morning</td>\n",
       "      <td>No Severe Delays</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>ANC</td>\n",
       "      <td>Not a Holiday</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Late Afternoon</td>\n",
       "      <td>No Severe Delays</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      FL_DATE ORIGIN        holiday DAY_OF_WEEK takeoff-time-of-day  \\\n",
       "0  2021-06-01    ANC  Not a Holiday     Tuesday     Early Afternoon   \n",
       "1  2021-06-01    ANC  Not a Holiday     Tuesday     Early Afternoon   \n",
       "2  2021-06-01    ANC  Not a Holiday     Tuesday       Early Evening   \n",
       "3  2021-06-01    ANC  Not a Holiday     Tuesday       Early Morning   \n",
       "4  2021-06-01    ANC  Not a Holiday     Tuesday      Late Afternoon   \n",
       "\n",
       "       severe_delay  size  \n",
       "0  No Severe Delays     8  \n",
       "1     Severe Delays     1  \n",
       "2  No Severe Delays     4  \n",
       "3  No Severe Delays    11  \n",
       "4  No Severe Delays     4  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll want the user to be able to graph data on 4 levels:\n",
    "1. All delays\n",
    "2. Delays by airport\n",
    "3. Delays by airline\n",
    "4. Delays by airline & airport\n",
    "\n",
    "So we work to pivot our data and save out files for these 4 levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delays by airport\n",
    "df_by_airport = pd.pivot_table(grouped_data, values='size', index=['FL_DATE', 'ORIGIN'],\n",
    "                    columns=['severe_delay'], aggfunc=np.sum, fill_value=0)\n",
    "df_by_airport = df_by_airport.reset_index()\n",
    "df_by_airport['percent-delayed'] = df_by_airport['Severe Delays'] / (df_by_airport['No Severe Delays'] + df_by_airport['Severe Delays'])\n",
    "\n",
    "# Delays by holiday\n",
    "df_by_holiday = pd.pivot_table(grouped_data, values='size', index=['holiday', 'ORIGIN'],\n",
    "                    columns=['severe_delay'], aggfunc=np.sum, fill_value=0)\n",
    "df_by_holiday = df_by_holiday.reset_index()\n",
    "df_by_holiday['percent-delayed'] = df_by_holiday['Severe Delays'] / (df_by_holiday['No Severe Delays'] + df_by_holiday['Severe Delays'])\n",
    "\n",
    "# Delays by holiday\n",
    "df_by_timeofday_weekday = pd.pivot_table(grouped_data, values='size', index=['DAY_OF_WEEK', 'takeoff-time-of-day','ORIGIN'],\n",
    "                    columns=['severe_delay'], aggfunc=np.sum, fill_value=0)\n",
    "df_by_timeofday_weekday = df_by_timeofday_weekday.reset_index()\n",
    "df_by_timeofday_weekday['percent-delayed'] =df_by_timeofday_weekday['Severe Delays'] / (df_by_timeofday_weekday['No Severe Delays'] + df_by_timeofday_weekday['Severe Delays'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's save these out to files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_by_airport.to_csv('data/prepared/delays-by-airport.csv', index=False)\n",
    "df_by_holiday.to_csv('data/prepared/delays-by-holiday.csv', index=False)\n",
    "df_by_timeofday_weekday.to_csv('data/prepared/df_by_timeofday_weekday.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
